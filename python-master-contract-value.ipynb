{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost\n",
    "from scipy import stats\n",
    "from statsmodels.stats import stattools\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "df = pd.read_csv('historical-data.csv')\n",
    "df_2018 = pd.read_csv('2018-19-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# density plot of historical salary\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "salary_dens, ax = plt.subplots()\n",
    "\n",
    "ax = sns.kdeplot(df['percent_of_cap'], ax = ax, shade = True, legend = False)\n",
    "\n",
    "salary_dens.suptitle(\"Distribution of salary\", weight = 'bold', size = 18)\n",
    "\n",
    "ax.set_xlabel(\"% of cap\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "\n",
    "salary_dens.text(x = -0.02, y = -0.08,\n",
    "    s = '___________________________________________________________',\n",
    "    fontsize = 14, color = 'grey', horizontalalignment='left', alpha = .3)\n",
    "\n",
    "salary_dens.text(x = -0.02, y = -.14,\n",
    "    s = 'https://dribbleanalytics.blog                     ',\n",
    "    fontsize = 14, fontname = 'Rockwell', color = 'grey', horizontalalignment='left')\n",
    "\n",
    "salary_dens.savefig('salary_dens.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to produce a scatter plot of a given statistic and salary\n",
    "\n",
    "def plot_salary_corr(stat):\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    x = df[stat]\n",
    "    y = df['percent_of_cap']\n",
    "    \n",
    "    ax.scatter(x, y, alpha = .25)\n",
    "    ax.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color = 'C1')\n",
    "\n",
    "    ax.set_xlabel(\"%s\" % stat.upper())\n",
    "    ax.set_ylabel(\"% of yearly cap\")\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    ax.set_title(\"r = %s\" %str(round(r_value, 3)), size = 14, fontname = 'Rockwell')\n",
    "    fig.suptitle('%s vs. salary' %stat.upper(), size = 18, weight = 'bold', y = 1.005)\n",
    "\n",
    "    fig.text(x = -0.03, y = -0.07,\n",
    "        s = '_____________________________________________________________',\n",
    "        fontsize = 14, color = 'grey', horizontalalignment='left', alpha = .3)\n",
    "\n",
    "    fig.text(x = -0.03, y = -.13,\n",
    "        s = 'https://dribbleanalytics.blog                     ',\n",
    "        fontsize = 14, fontname = 'Rockwell', color = 'grey', horizontalalignment='left')\n",
    "\n",
    "    fig.savefig('%s_salary.png' % stat, dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_salary_corr('pts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_salary_corr('ws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_salary_corr('age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define features and output, split data into 25% test size\n",
    "\n",
    "features = ['age', 'pts', 'trb', 'ast', 'stl', 'blk', 'ts', 'ws']\n",
    "output = ['percent_of_cap']\n",
    "\n",
    "train, test = train_test_split(df, test_size = 0.25, random_state = 0)\n",
    "\n",
    "xtrain = train[features]\n",
    "ytrain = train[output]\n",
    "\n",
    "xtest = test[features]\n",
    "ytest = test[output]\n",
    "\n",
    "print(\"Training size: \" + str(len(train)))\n",
    "print(\"Testing size: \" + str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation plot of features\n",
    "\n",
    "corr = df[features].corr()\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "corr_plot, ax = plt.subplots()\n",
    "\n",
    "cmap = plt.get_cmap('plasma')\n",
    "\n",
    "ax = sns.heatmap(corr, center=0, cmap = cmap,\n",
    "            square=True, linewidths=.5)\n",
    "\n",
    "ax.yaxis.set_tick_params(rotation=0)\n",
    "\n",
    "corr_plot.suptitle(\"Feature correlations\", weight = 'bold', size = 18)\n",
    "\n",
    "corr_plot.text(x = 0.17, y = 0,\n",
    "    s = '_____________________________________________',\n",
    "    fontsize = 14, color = 'grey', horizontalalignment='left', alpha = .3)\n",
    "\n",
    "corr_plot.text(x = 0.17, y = -.06,\n",
    "    s = 'https://dribbleanalytics.blog                     ',\n",
    "    fontsize = 14, fontname = 'Rockwell', color = 'grey', horizontalalignment='left')\n",
    "\n",
    "corr_plot.savefig('corr-plot.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid search function to return best parameters for each model\n",
    "\n",
    "cv = KFold(n_splits = 3, random_state = 0)\n",
    "\n",
    "def grid_search(model, grid):\n",
    "    clf = GridSearchCV(model, grid, cv = cv, n_jobs = -1, verbose = 2, iid = False, scoring = 'neg_mean_squared_error')\n",
    "    scores(clf)\n",
    "    \n",
    "    print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train and evaluate models\n",
    "\n",
    "def scores(model):\n",
    "    \n",
    "    model.fit(xtrain, ytrain.values.ravel())\n",
    "    y_pred = model.predict(xtest)\n",
    "    \n",
    "    print(\"MSE: %.3f\" % mean_squared_error(ytest, y_pred))\n",
    "    print('R2 score: %.3f' % r2_score(ytest, y_pred))\n",
    "\n",
    "    cv_score = cross_val_score(model, xtest, ytest.values.ravel(), cv = 3, scoring = 'neg_mean_squared_error')\n",
    "    print(\"MSE cross validation score: %0.3f (+/- %0.3f)\" % (cv_score.mean(), cv_score.std() * 2))\n",
    "    \n",
    "    cv_score = cross_val_score(model, xtest, ytest.values.ravel(), cv = 3, scoring = 'r2')\n",
    "    print(\"R2 cross validation score: %0.3f (+/- %0.3f)\" % (cv_score.mean(), cv_score.std() * 2))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "\n",
    "y_knn = scores(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [x for x in np.arange(5, 21)]\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "grid = {'n_neighbors': n_neighbors,\n",
    "        'weights': weights}\n",
    "\n",
    "grid_search(knn, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors = 19, weights = 'uniform')\n",
    "\n",
    "y_knn = scores(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "\n",
    "y_rf = scores(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "n_estimators = [int(x) for x in np.linspace(start = 25, stop = 250, num = 10)]\n",
    "random_state = [0]\n",
    "\n",
    "grid = {'max_depth': max_depth,\n",
    "        'max_features': max_features,\n",
    "        'n_estimators': n_estimators,\n",
    "        'random_state': random_state}\n",
    "\n",
    "grid_search(rf, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth = 10, max_features = 'auto', n_estimators = 250, random_state = 0)\n",
    "\n",
    "y_rf = scores(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state = 0)\n",
    "\n",
    "y_gbr = scores(gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ['ls', 'lad', 'huber']\n",
    "max_depth = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "n_estimators = [int(x) for x in np.linspace(start = 25, stop = 250, num = 10)]\n",
    "random_state = [0]\n",
    "\n",
    "grid = {'loss': loss,\n",
    "        'max_depth': max_depth,\n",
    "        'max_features': max_features,\n",
    "        'n_estimators': n_estimators,\n",
    "        'random_state': random_state}\n",
    "\n",
    "grid_search(gbr, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state = 0)\n",
    "\n",
    "y_gbr = scores(gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(objective = \"reg:squarederror\", random_state = 0)\n",
    "\n",
    "y_xgb = scores(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(start = 10, stop = 100, num = 10)]\n",
    "learning_rate = [0.01, 0.05, 0.1, 0.2]\n",
    "n_estimators = [int(x) for x in np.linspace(start = 25, stop = 250, num = 10)]\n",
    "booster = ['gbtree', 'gblinear', 'dart']\n",
    "\n",
    "grid = {'max_depth': max_depth,\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators': n_estimators,\n",
    "        'booster': booster}\n",
    "\n",
    "grid_search(xgb, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor(objective = \"reg:squarederror\", random_state = 0)\n",
    "\n",
    "y_xgb = scores(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardized residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert model y_pred values into standardized residuals\n",
    "\n",
    "def residuals(y_pred):\n",
    "    \n",
    "    resid = [i for i in (ytest.values.reshape(ytest.shape[0],) - y_pred)]\n",
    "    ssr = [i ** 2 for i in resid]\n",
    "    \n",
    "    ssr_sum = sum(ssr)\n",
    "        \n",
    "    stand_resid = []\n",
    "    for i in resid:\n",
    "        stand_resid.append(i / ((ssr_sum / (ytest.shape[0] - 2)) ** (1/2)))\n",
    "        \n",
    "    return stand_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_resid = residuals(y_knn)\n",
    "rf_resid = residuals(y_rf)\n",
    "gbr_resid = residuals(y_gbr)\n",
    "xgb_resid = residuals(y_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find outliers in standardized residuals (points more than 2 stdev away from mean)\n",
    "\n",
    "def outliers(x):\n",
    "    \n",
    "    np_list = np.array(x)\n",
    "    stdev = np.std(np_list)\n",
    "    mean = np.mean(np_list)\n",
    "\n",
    "    outliers = 0\n",
    "    for i in x:\n",
    "        if i < mean - 2 * stdev:\n",
    "            outliers += 1\n",
    "        elif i > mean + 2 * stdev:\n",
    "            outliers += 1\n",
    "\n",
    "    outlier_percent = 1 - outliers / ytest.shape[0]\n",
    "    outlier_string = \"{:.3%}\".format(outlier_percent)\n",
    "    \n",
    "    return outlier_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot standardized residuals\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "resid_fig, ax = plt.subplots(2, 2, sharex = True, sharey = True)\n",
    "\n",
    "norm = np.random.standard_normal(10000)\n",
    "\n",
    "ax1 = sns.kdeplot(knn_resid, ax=ax[0, 0])\n",
    "ax1 = sns.kdeplot(norm, ax=ax[0, 0])\n",
    "ax1.set_title(\"KNN: %s\" % outliers(knn_resid), size = 18, x = .485, ha = 'center')\n",
    "\n",
    "ax2 = sns.kdeplot(rf_resid, ax=ax[0, 1])\n",
    "ax2 = sns.kdeplot(norm, ax=ax[0, 1])\n",
    "ax2.set_title(\"RF: %s\" % outliers(rf_resid), size = 18, x = .485, ha = 'center')\n",
    "\n",
    "ax3 = sns.kdeplot(gbr_resid, ax=ax[1, 0])\n",
    "ax3 = sns.kdeplot(norm, ax=ax[1, 0])\n",
    "ax3.set_title(\"GBR: %s\" % outliers(gbr_resid), size = 18, x = .485, ha = 'center')\n",
    "\n",
    "ax4 = sns.kdeplot(xgb_resid, ax=ax[1, 1])\n",
    "ax4 = sns.kdeplot(norm, ax=ax[1, 1])\n",
    "ax4.set_title(\"XGB: %s\" % outliers(xgb_resid), size = 18, x = .485, ha = 'center')\n",
    "\n",
    "resid_fig.suptitle(\"Standardized Residuals \\n(normal dist. in red)\", weight = 'bold', size = 18, y = 1.12)\n",
    "\n",
    "resid_fig.text(x = 0, y = 0,\n",
    "    s = '_________________________________________________________',\n",
    "    fontsize = 14, color = 'grey', horizontalalignment='left', alpha = .3)\n",
    "\n",
    "resid_fig.text(x = 0, y = -.06,\n",
    "    s = 'https://dribbleanalytics.blog                     ',\n",
    "    fontsize = 14, fontname = 'Rockwell', color = 'grey', horizontalalignment='left')\n",
    "\n",
    "resid_fig.savefig('resid-fig-1.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapiro-Wilk test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform shapiro-wilk test for normality of residuals\n",
    "\n",
    "print(stats.shapiro(knn_resid))\n",
    "print(stats.shapiro(rf_resid))\n",
    "print(stats.shapiro(gbr_resid))\n",
    "print(stats.shapiro(xgb_resid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Q plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q-q plot compared to a normal distribution\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "qqplot, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex = True, sharey = True)\n",
    "\n",
    "stats.probplot(knn_resid, dist=\"norm\", plot=ax1)\n",
    "ax1.set_xlabel(\"\")\n",
    "ax1.set_ylabel(\"\")\n",
    "ax1.set_title(\"KNN\")\n",
    "\n",
    "stats.probplot(rf_resid, dist=\"norm\", plot=ax2)\n",
    "ax2.set_xlabel(\"\")\n",
    "ax2.set_ylabel(\"\")\n",
    "ax2.set_title(\"RF\")\n",
    "\n",
    "stats.probplot(gbr_resid, dist=\"norm\", plot=ax3)\n",
    "ax3.set_xlabel(\"\")\n",
    "ax3.set_ylabel(\"\")\n",
    "ax3.set_title(\"GBR\")\n",
    "\n",
    "stats.probplot(xgb_resid, dist = \"norm\", plot = ax4)\n",
    "ax4.set_xlabel(\"\")\n",
    "ax4.set_ylabel(\"\")\n",
    "ax4.set_title(\"XGB\")\n",
    "\n",
    "qqplot.text(0.5, -0.02, 'Theoretical Quantiles', ha='center', va='center', size = 18)\n",
    "qqplot.text(0.01, 0.5, 'Ordered Values', ha='center', va='center', rotation='vertical', size = 18)\n",
    "\n",
    "qqplot.text(x = 0, y = -0.05,\n",
    "    s = '_______________________________________________________________',\n",
    "    fontsize = 14, color = 'grey', horizontalalignment='left', alpha = .3)\n",
    "\n",
    "qqplot.text(x = 0, y = -.1,\n",
    "    s = 'https://dribbleanalytics.blog                     ',\n",
    "    fontsize = 14, fontname = 'Rockwell', color = 'grey', horizontalalignment='left')\n",
    "\n",
    "qqplot.savefig('qqplot.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durbin-Watson test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform durbin-watson test for autocorrelation\n",
    "\n",
    "print(stattools.durbin_watson(knn_resid))\n",
    "print(stattools.durbin_watson(rf_resid))\n",
    "print(stattools.durbin_watson(gbr_resid))\n",
    "print(stattools.durbin_watson(xgb_resid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create predictions from each model\n",
    "\n",
    "def make_pred(model_list, df_pred):\n",
    "    prob_list = []\n",
    "    \n",
    "    for i in model_list:\n",
    "        prob_list.append(i.predict(df_pred))\n",
    "        \n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean predictions and save to csv\n",
    "\n",
    "prob_list = make_pred([knn, rf, gbr, xgb], df_2018[features])\n",
    "\n",
    "pred_vals = pd.DataFrame(data = np.transpose(prob_list), columns = ['knn', 'rf', 'gbr', 'xgb'])\n",
    "\n",
    "pred_vals['avg'] = (pred_vals['knn'] + pred_vals['rf'] + pred_vals['gbr'] + pred_vals['xgb']) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary_pred = df_2018.join(pred_vals)\n",
    "df_salary_pred['diff'] = df_salary_pred['avg'] - df_salary_pred['percent_of_cap']\n",
    "\n",
    "df_salary_pred.to_csv('salary-pred.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example on the effect of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how Luka Doncic's predicted salary changes if we suppose he's 27 years old instead of 19\n",
    "\n",
    "doncic = df_2018[df_2018['player'] == 'Luka Doncic'].reset_index(drop = True)\n",
    "\n",
    "doncic.loc[1] = doncic.loc[0]\n",
    "doncic.loc[1, 'age'] = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doncic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_list = make_pred([knn, rf, gbr, xgb], doncic[features])\n",
    "\n",
    "pred_vals = pd.DataFrame(data = np.transpose(prob_list), columns = ['knn', 'rf', 'gbr', 'xgb'])\n",
    "\n",
    "pred_vals['avg'] = (pred_vals['knn'] + pred_vals['rf'] + pred_vals['gbr'] + pred_vals['xgb']) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary_pred = pd.read_csv('salary-pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare distribution of predicted salary to distribution of actual salary\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "pred_obs_dens, ax = plt.subplots()\n",
    "\n",
    "ax = sns.kdeplot(df_salary_pred['percent_of_cap'], ax = ax, shade = True, label = 'Observed salary')\n",
    "ax = sns.kdeplot(df_salary_pred['avg'], ax = ax, shade = True, label = 'Predicted salary')\n",
    "\n",
    "ax.set_xlabel(\"% of cap\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "\n",
    "pred_obs_dens.suptitle(\"Observed and predicted salary\", weight = 'bold', size = 18)\n",
    "\n",
    "pred_obs_dens.text(x = -0.02, y = -0.08,\n",
    "    s = '_____________________________________________________________',\n",
    "    fontsize = 14, color = 'grey', horizontalalignment='left', alpha = .3)\n",
    "\n",
    "pred_obs_dens.text(x = -0.02, y = -.14,\n",
    "    s = 'https://dribbleanalytics.blog                     ',\n",
    "    fontsize = 14, fontname = 'Rockwell', color = 'grey', horizontalalignment='left')\n",
    "\n",
    "pred_obs_dens.savefig('pred_obs_dens.png', dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make bar graph from predictions\n",
    "\n",
    "def make_plot(df_rows, color, title, neg_bool, height, file_name):\n",
    "    \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    y = df_rows['diff']\n",
    "    labels = df_rows['player']\n",
    "    x = range(len(y))\n",
    "    \n",
    "    ax.bar(x, y, width = .7, edgecolor = 'white', color = color, linewidth = 4, label = 'Predicted')\n",
    "\n",
    "    rects = ax.patches\n",
    "    \n",
    "    if neg_bool == True:\n",
    "        for rect, label in zip(rects, labels):\n",
    "            ax.text(rect.get_x() + rect.get_width() / 1.75, height, label,\n",
    "            ha='center', va='bottom', rotation = 'vertical', color = 'black')\n",
    "    else:\n",
    "        for rect, label in zip(rects, labels):\n",
    "            ax.text(rect.get_x() + rect.get_width() / 2.5, -height, label,\n",
    "            ha='center', va='top', rotation = -90, color = 'black')\n",
    "\n",
    "    fig.suptitle(\"%s\" % title, weight = 'bold', size = 18)\n",
    "    ax.xaxis.set_visible(False)\n",
    "    \n",
    "    ax.set_ylabel(\"Expected - actual % of cap\")\n",
    "\n",
    "    fig.text(x = -0.08, y = 0.03,\n",
    "        s = '______________________________________________________________',\n",
    "        fontsize = 14, color = 'grey', horizontalalignment='left', alpha = .3)\n",
    "\n",
    "    fig.text(x = -0.08, y = -.03,\n",
    "        s = 'https://dribbleanalytics.blog                     ',\n",
    "        fontsize = 14, fontname = 'Rockwell', color = 'grey', horizontalalignment='left')\n",
    "\n",
    "    fig.savefig('%s.png' % file_name, dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val = df_salary_pred.sort_values(by = 'diff', ascending = False).reset_index(drop = True).iloc[0:10]\n",
    "\n",
    "make_plot(best_val, 'springgreen', \"Best bargain contracts\", True, 0.005, 'best-val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_val = df_salary_pred.sort_values(by = 'diff', ascending = True).reset_index(drop = True).iloc[0:10]\n",
    "\n",
    "make_plot(worst_val, 'lightcoral', \"Worst value contracts\", False, 0.005, 'worst-val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby into team sum of difference and prepare data to run for make plot function\n",
    "\n",
    "team_cap = df_salary_pred.groupby('tm')['diff'].sum().sort_values()\n",
    "team_cap = pd.DataFrame(team_cap).reset_index().rename(columns = {'tm': 'player'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_team = team_cap.sort_values(by = 'diff', ascending = False).iloc[:10]\n",
    "\n",
    "make_plot(best_team, 'springgreen', \"Best bargaining teams\", True, 0.01, 'best-val-teams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_team = team_cap.sort_values(by = 'diff', ascending = True).iloc[:10]\n",
    "\n",
    "make_plot(worst_team, 'lightcoral', \"Worst bargaining teams\", False, 0.01, 'worst-val-teams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare shap plots\n",
    "\n",
    "shap.initjs()\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a plot of shap values given the values and model name\n",
    "\n",
    "def plot_shap(shap_values, model_name):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax = shap.summary_plot(shap_values, xtrain, show = False)\n",
    "    fig.suptitle(\"%s Shapley values\" % model_name.upper(), weight = 'bold', size = 18)\n",
    "    \n",
    "    fig.text(x = 0, y = -0.03,\n",
    "        s = '________________________________________________________________________',\n",
    "        fontsize = 14, color = 'grey', horizontalalignment='left', alpha = .3)\n",
    "\n",
    "    fig.text(x = 0, y = -.075,\n",
    "        s = 'https://dribbleanalytics.blog                     ',\n",
    "        fontsize = 12, fontname = 'Rockwell', color = 'grey', horizontalalignment='left')\n",
    "\n",
    "    fig.savefig('%s_shap.png' % model_name, dpi = 400, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_k = shap.kmeans(xtrain, 5)\n",
    "\n",
    "explainer = shap.KernelExplainer(knn.predict, knn_k)\n",
    "shap_values = explainer.shap_values(xtrain)\n",
    "\n",
    "plot_shap(shap_values, 'knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values = explainer.shap_values(xtrain)\n",
    "\n",
    "plot_shap(shap_values, 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(gbr)\n",
    "shap_values = explainer.shap_values(xtrain)\n",
    "\n",
    "plot_shap(shap_values, 'gbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb)\n",
    "shap_values = explainer.shap_values(xtrain)\n",
    "\n",
    "plot_shap(shap_values, 'xgb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
